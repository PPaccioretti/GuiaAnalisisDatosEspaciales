<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.313">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="author" content="<p>“Mariano Córdoba, Pablo Paccioretti, Franca Giannini Kurina, Cecilia Bruno, Mónica Balzarini”</p>">
<meta name="description" content="DISEMINACIÓN CIENTÍFICA Y TRASNFERENCIA DE RESULTADOS DE INVESTIGACIÓN, PROMOVIDAS POR EL MINISTERIO DE CIENCIA Y TECNOLOGÍA DE LA PROVINCIA DE CÓRDOBA.">
<title>Guía para el análisis de datos espaciales. Aplicaciones en agricultura - 2&nbsp; Caracterización de variabilidad espacial</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./Parte1_cap_c_CarcVarEspMultiCapa.html" rel="next">
<link href="./Parte1_cap_a_MjoDtosEsp.html" rel="prev">
<link href="./figuras/cover.jpg" rel="icon" type="image/jpeg">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar"
  }
}</script><style>html{ scroll-behavior: smooth; }</style>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-154490537-1', 'auto');
  ga('send', 'pageview');

</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }"><div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">
<span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Caracterización de variabilidad espacial</span>
</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Guía para el análisis de datos espaciales. Aplicaciones en agricultura</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/PPaccioretti/GuiaAnalisisDatosEspaciales" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
    <a href="./GuiaAnalisisDatosEspaciales.pdf" title="Download PDF" class="sidebar-tool px-1"><i class="bi bi-file-pdf"></i></a>
  <a href="" class="quarto-reader-toggle sidebar-tool" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Prólogo</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Aproximaciones metodológicas</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Parte1_cap_a_MjoDtosEsp.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Manejo de datos espaciales</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Parte1_cap_b_CarcVarEsp.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Caracterización de variabilidad espacial</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Parte1_cap_c_CarcVarEspMultiCapa.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Caracterización de variabilidad espacial con múltiples capas de datos</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Parte1_cap_d_PredMultipleCapa.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Predicción con múltiples capas de datos</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Análisis de datos a escala fina</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Parte2_cap_a_EscFinaImplR.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Implementación con R</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Parte2_cap_b_EscFinaImplInfo.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Implementación con InfoStat</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">Análisis de datos a escala regional</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Parte3_cap_a_EscRegionImplR.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Bases de datos regionales</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./referencias.html" class="sidebar-item-text sidebar-link">Referencias</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">Apéndices</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./anexoR.html" class="sidebar-item-text sidebar-link">Introducción a R</a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><!-- margin-sidebar --><div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Tabla de contenidos</h2>
   
  <ul>
<li>
<a href="#semivariogramas" id="toc-semivariogramas" class="nav-link active" data-scroll-target="#semivariogramas"><span class="toc-section-number">2.1</span>  Semivariogramas</a>
  <ul class="collapse">
<li><a href="#ajuste-de-semivariogramas" id="toc-ajuste-de-semivariogramas" class="nav-link" data-scroll-target="#ajuste-de-semivariogramas"><span class="toc-section-number">2.1.1</span>  Ajuste de semivariogramas</a></li>
  </ul>
</li>
  <li>
<a href="#correlaci%C3%B3n-espacial-bivariada" id="toc-correlación-espacial-bivariada" class="nav-link" data-scroll-target="#correlaci%C3%B3n-espacial-bivariada"><span class="toc-section-number">2.2</span>  Correlación espacial bivariada</a>
  <ul class="collapse">
<li><a href="#coeficiente-de-correlaci%C3%B3n" id="toc-coeficiente-de-correlación" class="nav-link" data-scroll-target="#coeficiente-de-correlaci%C3%B3n"><span class="toc-section-number">2.2.1</span>  Coeficiente de correlación</a></li>
  <li><a href="#coeficiente-de-co-dispersi%C3%B3n" id="toc-coeficiente-de-co-dispersión" class="nav-link" data-scroll-target="#coeficiente-de-co-dispersi%C3%B3n"><span class="toc-section-number">2.2.2</span>  Coeficiente de co-dispersión</a></li>
  </ul>
</li>
  <li>
<a href="#interpolaci%C3%B3n-kriging" id="toc-interpolación-kriging" class="nav-link" data-scroll-target="#interpolaci%C3%B3n-kriging"><span class="toc-section-number">2.3</span>  Interpolación Kriging</a>
  <ul class="collapse">
<li><a href="#kriging-ordinario" id="toc-kriging-ordinario" class="nav-link" data-scroll-target="#kriging-ordinario"><span class="toc-section-number">2.3.1</span>  Kriging ordinario</a></li>
  <li><a href="#kriging-en-bloques" id="toc-kriging-en-bloques" class="nav-link" data-scroll-target="#kriging-en-bloques"><span class="toc-section-number">2.3.2</span>  Kriging en bloques</a></li>
  <li><a href="#kriging-local" id="toc-kriging-local" class="nav-link" data-scroll-target="#kriging-local"><span class="toc-section-number">2.3.3</span>  Kriging local</a></li>
  <li><a href="#kriging-universal" id="toc-kriging-universal" class="nav-link" data-scroll-target="#kriging-universal"><span class="toc-section-number">2.3.4</span>  Kriging universal</a></li>
  <li><a href="#validaci%C3%B3n-cruzada" id="toc-validación-cruzada" class="nav-link" data-scroll-target="#validaci%C3%B3n-cruzada"><span class="toc-section-number">2.3.5</span>  Validación cruzada</a></li>
  </ul>
</li>
  </ul><div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/PPaccioretti/GuiaAnalisisDatosEspaciales/edit/main/Parte1_cap_b_CarcVarEsp.qmd" class="toc-action">Editar esta página</a></p><p><a href="https://github.com/PPaccioretti/GuiaAnalisisDatosEspaciales/issues/new" class="toc-action">Informar de un problema</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title d-none d-lg-block">
<span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Caracterización de variabilidad espacial</span>
</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Código</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header><p>Denotamos el proceso espacial en <span class="math inline">\(d\)</span> dimensiones como: <span class="math inline">\({Z(s): s\in\ D\subset R^d}\)</span> donde <span class="math inline">\(Z\)</span> denota el atributo que observamos, <span class="math inline">\(s\)</span> es la ubicación en la cual <span class="math inline">\(Z\)</span> es observada y es un vector de coordenadas de dimensiones <span class="math inline">\(n\times2\)</span> y <span class="math inline">\(D\)</span> es el dominio. Los procesos espaciales que se abordarán en este libro son procesos bidimensionales, <span class="math inline">\(d=2\)</span> y <span class="math inline">\(s=x,y \prime\)</span> son tratadas como coordenadas cartesianas. Cuando la <span class="math inline">\(d\)</span> es mayor a 1, el proceso estocástico subyacente es definido como un campo aleatorio.</p>
<p>La colección de n observaciones georreferenciadas que conforman un conjunto de datos espaciales deben entenderse como una muestra de tamaño uno de una distribución n-dimensional. En este caso la <span class="math inline">\(E\left[Z(s)\right]=\mu(s)\)</span> representa el promedio del atributo en la ubicación <span class="math inline">\(s\)</span> sobre la distribución de una posible realización. Si quisiéramos determinar el valor esperado para un sitio no observado, para <span class="math inline">\(s_0\)</span>, sería necesario repetir las observaciones en ese punto, pero usualmente solo se tiene una observación por sitio. Sólo se puede hacer inferencia basada en una muestra de tamaño uno, bajo condiciones de estacionaridad, es decir cuando la esperanza es la misma en todos los puntos. Por ello, un supuesto importante para el análisis de los datos espaciales será el de estacionaridad. Bajo estas condiciones la variabilidad espacial podrá ser caracterizada a través de funciones basadas solo en varianzas y covarianzas o autocorrelaciones en los datos espaciales.</p>
<p>La autocorrelación espacial mide la correlación lineal entre los valores de una variable aleatoria y los de otra construida a partir del rezago de la primera. Puede interpretarse como medida de la coincidencia de valores similares de una variable en espacios geográficos cercanos, es decir, la variable tiende a asumir valores similares en unidades geográficamente cercanas. Mediado por la distancia, queremos saber qué tan semejante o diferente es el valor de la variable “consigo misma”. Luego, para una variable espacialmente autocorrelacionada, los valores observados en el espacio no serán aleatorios, sino que estarán espacialmente relacionados.</p>
<p>La autocorrelación puede ser global o local. El primer tipo considera los valores de todas las observaciones, mientras el segundo solo los valores de las observaciones de un sitio respecto a los de observaciones vecinas. En ambos casos, la autocorrelación espacial puede ser medida en términos de su intensidad; una autocorrelación espacial fuerte significa que los valores del atributo de las unidades de observación geográfica vecinas muy parecidos o predecibles desde el valor del sitio, el caso contrario se produce cuando la distribución en sitios vecinos refleja un patrón aleatorio. El análisis de autocorrelación espacial requiere contar con una medida de correlación lineal apropiada para medir grados de semejanza entre las observaciones en un sitio y en su entorno.</p>
<p>Los índices de autocorrelación espacial expresan de manera formal el grado de correlación lineal entre las variables aleatorias representadas funcionalmente por el vector de valores observados y el vector de medias ponderadas espacialmente en las unidades vecinas, llamado el vector con <em>lag espacial</em>. El cálculo de estos índices en un espacio continuo requiere la definición de una matriz de ponderación espacial. Ésta puede tener elementos binarios para indicar cuáles son las observaciones que pertenecen al vecindario de cada dato, <em>i.e.</em> las observaciones “conectadas” con cada dato.</p>
<p>También puede tener como elementos, los valores de un coeficiente de continuidad que mide el grado de conexión entre un par de datos. El elemento <span class="math inline">\(w_{ij}\)</span> de la matriz de ponderaciones <span class="math inline">\(W\)</span>, es el peso aplicado a la comparación de las observaciones en la posición <span class="math inline">\(i\)</span> y la posición <span class="math inline">\(j\)</span>. Usualmente se utilizan redes de conexión que derivan en un matriz de pesos espaciales. La red de vecindarios también puede ser definida considerando puntos vecinos a aquellos contiguos ubicados entre un límite inferior y superior, previamente preestablecido. Cuando las entidades se encuentran distribuidas en forma homogénea en el espacio, suele recomendarse la red de conexión obtenida por el método de triangulación de Delaunay Las redes de conexión también pueden ser adaptadas manualmente pudiéndose excluir contactos entre sitios cercanos o incluir relaciones entre sitios lejanos.</p>
<p>Por ejemplo, el índice de autocorrelación espacial de Geary (GI), expresa la magnitud de las desviaciones entre observaciones en diferentes localizaciones. Siendo <span class="math inline">\(w..\)</span> la suma de todos los pesos, la expresión del índice es:</p>
<p><span class="math display">\[GI=\frac{(n-1)\sum_{i}\sum_{j}{w_{ij}(Z(s_i)\ -\ Z(s_j))^2}}{2w..\sum_{i}{(Z(s_i)-\bar{z})}^2}\]</span></p>
<p>El valor de GI se encuentra en el intervalo [0,2]. Si no hay autocorrelación espacial, el valor esperado de GI es 1. Valores del índice entre 1 y 2 indican autocorrelación espacial negativa, y entre 0 y 1 autocorrelación espacial positiva. Este índice se relaciona inversamente con el índice MI, es decir valores más cercanos a 0 sugieren autocorrelaciones positivas más fuerte. GI es más sensible a pequeñas diferencias entre posiciones vecinas que el IM. Los índices de autocorrelación espacial local son calculados para cada sitio y usan solo ponderadores para las distancias entre las observaciones de ese sitio y las restantes. El índice LM fue descripto anteriormente para ejemplificar su uso en la detección de <em>outliers</em>. Otro índice de autocorrelación espacial local es el índice de Getis Ord (GO) el que se calcula como la suma de los valores observados para la <span class="math inline">\(j-ésima\)</span> variable en el vecindario centrado del <span class="math inline">\(i-ésimo\)</span> píxel, en relación con la suma de todas las observaciones. Su expresión estandarizada es:</p>
<p><span class="math display">\[{GO}_i=\frac{\sum_{i=1}^{m}{w_{i,i^\prime}{Z(s}_{i^\prime})-\bar{Z}\sum_{i=1}^{m}w_{i,i^\prime}}}{S\sqrt{\frac{m\sum_{i=1}^{m}{w_{i\neq i^\prime}^2-\left(\sum_{i=1}^{m}w_{i\neq i^\prime}\right)^2}}{n-1}}}\]</span></p>
<p>donde <span class="math inline">\(w_i\)</span> representa pesos espaciales en un vecindario del <span class="math inline">\(i-ésimo\)</span> píxel de tamaño <span class="math inline">\(m\)</span>. Valores positivos de GO indican grupos locales de valores altos para la variable alrededor de la <span class="math inline">\(i-ésima\)</span> ubicación, mientras que valores negativos indican grupos locales de valores bajos alrededor de la <span class="math inline">\(i-ésima\)</span> ubicación. Para evaluar la significancia estadística de estos índices es posible utilizar procedimientos del tipo Monte Carlo <span class="citation" data-cites="Babai_1979">(<a href="referencias.html#ref-Babai_1979" role="doc-biblioref">Babai 1979</a>)</span>. Las ubicaciones son permutadas en el espacio para obtener la distribución del índice bajo la hipótesis nula de distribución aleatoria.</p>
<section id="semivariogramas" class="level2" data-number="2.1"><h2 data-number="2.1" class="anchored" data-anchor-id="semivariogramas">
<span class="header-section-number">2.1</span> Semivariogramas</h2>
<p>La dependencia espacial o autocorrelación espacial, puede modelarse mediante un semivariograma. Esta función permite analizar la estructura y la naturaleza de la dependencia espacial en un conjunto de observaciones geo-referenciadas. El proceso espacial puede ser representado por el siguiente modelo estadístico:</p>
<p><span class="math display">\[Z\left(s\right)=\mu+\varepsilon\left(s\right)\]</span></p>
<p>donde <span class="math inline">\(\mu\)</span> es la media del proceso y <span class="math inline">\(\varepsilon\left(s\right)\)</span> es un término de error aleatorio con media cero y covarianza <span class="math inline">\(C(h)\)</span>, donde <span class="math inline">\(h\)</span> es el <em>lag</em> o separación en el espacio entre dos sitios particulares. Un campo aleatorio <span class="math inline">\({Z(s):\ s\in\ D\subset R^d}\)</span> es estrictamente estacionario si la distribución espacial es invariante bajo traslación de las coordenadas a través de todo el dominio (estacionaridad en sentido fuerte). La estacionaridad de segundo orden, o estacionaridad en sentido débil, se produce cuando <span class="math inline">\(E\left[Z\left(s\right)\right]=\mu\left(s\right)\)</span> y <span class="math inline">\(Cov\big[Z(s),Z(s+h)\big]=C(h)\)</span>. Es decir, en un campo aleatorio estacionario de segundo orden, la media es constante y la covarianza entre observaciones sobre diferentes posiciones, es función de la separación espacial entre los sitios en las que son tomadas, <span class="math inline">\(C(h)\)</span> es la función de covarianza del proceso espacial. La estacionaridad de primero orden implica la estacionaridad de segundo orden, pero la inversa no es cierta.</p>
<p>Dado que <span class="math inline">\(C(h)\)</span> no depende del valor de las coordenadas y <span class="math inline">\(Cov\big[Z(s),Z(s+0)\big]= Var \big[Z(s)\big]=C\)</span>, en procesos estacionarios de segundo orden, la variabilidad es la misma en todas partes, <em>i.e.</em> <span class="math inline">\(Var [Z(s)]=\sigma^2\)</span> no es una función de la ubicación espacial. En síntesis, un proceso espacial estacionario de segundo orden tiene media y varianza constantes y la función de covarianza no depende en absoluto de las coordenadas. A <span class="math inline">\(C\left(h\right)\)</span> también se la conoce como función de autocovarianza y depende de la escala en la cual <span class="math inline">\(Z\)</span> fue medida. Resulta más conveniente y fácil de interpretar si se la hace adimensional convirtiéndola en autocorrelación <span class="math inline">\(\rho\left(h\right)=\frac{C(h)}{C}\)</span>. La función <span class="math inline">\(\rho\left(h\right)\)</span> se denomina correlograma del proceso espacial.</p>
<p>Aún si <span class="math inline">\(Z(h)\)</span> no es estacionaria de segundo orden, el incremento <span class="math inline">\(Z(s)-Z(s+h)\)</span> puede serlo. Un proceso que tiene esta característica se dice que tiene estacionaridad intrínseca. Esto se produce si <span class="math inline">\(E\big[(Z(s)\big]=\mu\)</span> y <span class="math inline">\(\frac{1}{2}Var\big[Z(s)-Z(s+h)\big]=\gamma(h)\)</span>.</p>
<p>La función <span class="math inline">\(\gamma(h)\)</span> es llamada semivariograma del proceso espacial. La clase de procesos intrínsecamente estacionario es más grande que la clase de procesos estacionarios de segundo orden Notar que un proceso espacial que presenta estacionaridad intrínseca no es necesariamente estacionario de segundo orden. En condiciones de estacionaridad de segundo orden la función de covarianza es el semivariograma.</p>
<p>Un proceso que parece estacionario en una escala podría no serlo a otra escala (<em>i.e.</em> presentar una tendencia o un componente sistemático). En el modelo, <span class="math inline">\(\mu\)</span> será remplazado por <span class="math inline">\(\mu(s)\)</span>, <em>i.e.</em> término de tendencia determinístico para el sitio <span class="math inline">\(s\)</span>. El semivariograma, en estos casos se calcula sobre los residuos del modelo. El semivariograma, puede interpretarse como función de la varianza de la diferencia entre las observaciones. Si el semivariograma es sólo una función de la distancia entre observaciones, entonces es conocido como semivariograma isotrópico, <em>i.e.</em> no depende de la dirección. El semivariograma y covariograma son parámetros del proceso espacial y juegan un rol crítico en los métodos geoestadísticos de análisis de datos espaciales.</p>
<p>Un primer paso para caracterizar la variación espacial en un dominio continuo es construir un semivariograma experimental o empírico. Una fórmula usual para computar semivariogramas, es conocida como estimador de los momentos de Matheron</p>
<p><span class="math display">\[\hat{\gamma}(h)=\frac{1}{2 m (h)}\sum_{i=1}^{m(h)} \Big\{Z(s_i)-Z(s_i+h) \Big\}^2\]</span></p>
<p>donde <span class="math inline">\(m(h)\)</span> es el número de pares de puntos separados por la particular distancia <span class="math inline">\(h\)</span>. El otro estimador ampliamente usado es el estimador de Cressie- Hawkins o estimador robusto cuya fórmula se expresa como</p>
<p><span class="math display">\[2 \widetilde{\gamma}(h)= \frac{\Big[ \frac{1}{m(h)} \sum_{i=1}^{m(h)} \Big| Z(s_i) - Z(s_i + h) \Big| ^\frac{1}{2}  \Big] ^4}{0,457 + \frac{0,494}{m(h)} + \frac{0,045}{m^2(h)}}\]</span></p>
<p>Este estimador puede ser menos sesgado que <span class="math inline">\(\hat{\gamma}(h)\)</span> cuando la varianza residual es relativamente pequeña siendo también menos sensible a la presencia de valores externos. El estimador muestra típicamente menor variación en distancias pequeñas y también resulta en valores generalmente más pequeños que el estimador de los momentos de Matheron. Computando cualquiera de los dos estimadores, para las distancias <span class="math inline">\(h\)</span>, obtenemos un conjunto ordenado de semivarianzas. Tales semivarianzas graficadas en función h constituye el semivariograma empírico o experimental.</p>
<p>Los parámetros de un semivariograma son: la varianza nugget o simplemente nugget <span class="math inline">\((C_0)\)</span>, la varianza estructural o sill parcial <span class="math inline">\((C)\)</span> y el rango <span class="math inline">\((R)\)</span>. La asíntota es llamada la meseta del semivariograma o <span class="math inline">\(C\)</span> y el lag o distancia <span class="math inline">\(h^\ast\)</span> en el cual la meseta es alcanzada se denomina <span class="math inline">\(R\)</span> o rango. Observaciones <span class="math inline">\(Z(s_i)\)</span> y <span class="math inline">\(Z(s_j)\)</span> para las cuales <span class="math inline">\(|| Z(s_i) - Z(s_j)|| \geq h^\ast\)</span> son espacialmente independientes. Si el semivariograma alcanza la meseta asintóticamente, se define el rango práctico <span class="math inline">\((R_P)\)</span> como la distancia en el cual la semivarianza alcanza el 95% de la varianza umbral o total.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="figuras/semivEmpTeo.png" class="img-fluid figure-img" width="688"></p>
<p></p><figcaption class="figure-caption">a) Semivariograma empírico. b) Semivariograma teórico, modelo esférico. Se representan los tres parámetros que lo definen: rango, sill y efecto pepita o nugget.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>En la práctica el semivariograma empírico <span class="math inline">\(\hat{\gamma}(h)\)</span> puede no pasar a través del origen. La ordenada al origen del semivariograma representa a <span class="math inline">\(C_{0}\)</span>, por lo tanto <span class="math inline">\(C_0=\lim_{h\rightarrow0}{g(h)}\neq0\)</span>. Este parámetro representa la suma de errores aleatorios o no estructurados espacialmente, así como errores asociados con la variabilidad espacial a escalas más finas que la usada para realizar las mediciones. Un alto valor de <span class="math inline">\(C_0\)</span> indica que la mayoría de la variación espacial no es explicada por el semivariograma. La varianza umbral o sill se obtiene sumando las varianzas antes mencionadas (<span class="math inline">\(C_0+C\)</span>) y es la varianza de observaciones independientes, es decir observaciones que fueron tomadas a mayor distancia que <span class="math inline">\(R\)</span>.</p>
<p>Un semivariograma se define como anisotrópico si cambia en alguna forma respecto a la dirección que se considere. Si el semivariograma no solo depende de la longitud del vector h sino también de la dirección del vector entonces el semivariograma es anisotrópico. En los casos isotrópicos, los contornos de isocorrelación son esféricos, mientras que en el caso que haya anisotropía los contornos de isocorrelación son elípticos. Se reconocen dos tipos de anisotropía: anisotropía geométrica y anisotropía zonal. Anisotropía geométrica ocurre cuando el rango del semivariograma cambia en las distintas direcciones, pero no la varianza sill, por lo tanto, la correlación es más fuerte en una dirección que en otra. Anisotropía zonal existe cuando la varianza estructural del semivariograma cambia con la dirección. Anisotropía geométrica significa que la correlación es más fuerte en una dirección que en otra.</p>
<p>Una forma en que la anisotropía geométrica puede ser identificada es graficando un semivariograma experimental direccional. Diferencias en el semivariograma muestral usando diferentes ángulos al computarlo, es indicador de anisotropía. La anisotropía geométrica puede ser modelada cambiando el modelo de semivariograma por un proceso isotrópico transformando las coordenadas. Los modelos teóricos de semivariograma más usados en predicción espacial están basados son isotrópicos, por lo que es necesario una corrección en casos de anisotropía para poder utilizar la metodología clásica de predicción en geoestadística. El radio de anisotropía, es decir, el cociente entre los rangos de la dirección de máximo y mínima variación es usada para mesurar anisotropía. Algunos autores consideran que existe anisotropía significativa si el radio de anisotropía es mayor a 2,5.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="figuras/modeloIsoAniso.png" class="img-fluid figure-img" width="302"></p>
<p></p><figcaption class="figure-caption">a) Modelo isotrópico. b) Modelo anisotrópico, con ángulo de anisotropía de 45º y un radio de anisotropía de 0,5.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>En los procesos espaciales continuos, caracterizados por semivariogramas suelen obtenerse medidas del grado de estructuración espacial. Una de éstas es la varianza estructural relativa (RSV):</p>
<p><span class="math display">\[RSV=\Bigg(\frac{C}{C+C_0}\Bigg)\times100\%\]</span></p>
<p>Un valor alto de RSV indica que las predicciones geoestadísticas serán más eficientes que aquellas obtenidas con métodos de predicción que ignoran la información espacial. Un valor alto de RSV también indica una continuidad mayor del proceso espacial. <span class="citation" data-cites="Zimback_2001">Zimback (<a href="referencias.html#ref-Zimback_2001" role="doc-biblioref">2001</a>)</span> establece que el grado de dependencia espacial puede ser clasificado como: <span class="math inline">\(RSV \leq 25\%\)</span> bajo, <span class="math inline">\(RSV\)</span> entre <span class="math inline">\(25\%\)</span> y <span class="math inline">\(75\%\)</span> medio y <span class="math inline">\(RSV \geq 75\%\)</span> alto. También se puede calcular el cociente <span class="math inline">\(\frac{C_0}{C_0+C}\)</span> y en función de éste hablar de estructura espacial fuerte cuando el cociente es: <span class="math inline">\(\leq 25\%\)</span>, intermedia si el mismo se encuentra entre 25% y 75% y débil si el mismo es mayor al 75%.</p>
<section id="ajuste-de-semivariogramas" class="level3" data-number="2.1.1"><h3 data-number="2.1.1" class="anchored" data-anchor-id="ajuste-de-semivariogramas">
<span class="header-section-number">2.1.1</span> Ajuste de semivariogramas</h3>
<p>El semivariograma empírico <span class="math inline">\(\hat{\gamma}(h)\)</span>, es un estimador insesgado de <span class="math inline">\(\gamma(h)\)</span>, pero provee solo estimaciones para un conjunto finito de distancias. Para obtener estimaciones de <span class="math inline">\(\gamma(h)\)</span>, para cualquier lag, al semivariograma empírico se le ajusta un modelo teórico. El análisis geoestadístico sigue entonces estos dos pasos: 1) obtención del semivariograma empírico y 2) ajuste de un modelo teórico de semivariograma al semivariograma empírico.</p>
<p>Las funciones que sirven como modelos teóricos de semivariograma deben ser condicionalmente definidas positivas. Existen varios modelos teóricos para funciones semivariogramas, entre los que se encuentran el modelo nugget, el lineal, el esférico, el gaussiano y el exponencial (Figura @ref(fig:figSemivariogramas)). El semivariograma de un proceso de ruido blanco (modelo nugget), donde los valores <span class="math inline">\(Z\left(s\right)\)</span> se comportan como muestras aleatorias, todas con igual media y varianza sin correlación entre ellas. Este modelo suele ajustar el semivariograma empírico cuando la menor distancia de muestreo en los datos es mayor que el rango del proceso espacial.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="figuras/Semivariogramas.jpg" class="img-fluid figure-img" width="423"></p>
<p></p><figcaption class="figure-caption">Funciones de semivariograma para el modelo exponencial, esférico y gaussiano. <span class="math inline">\(C_0\)</span>=2, <span class="math inline">\(C\)</span>=10 y <span class="math inline">\(R\)</span>=200</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>El modelo esférico es uno de los más populares entre los modelos de semivariograma. Tiene dos características principales: un comportamiento lineal cerca del origen y el hecho de que a la distancia <span class="math inline">\(R\)</span> el semivariograma encuentra la meseta y después de esta se mantiene llano. El modelo exponencial se aproxima a la meseta del semivariograma asintóticamente cuando <span class="math inline">\(\parallel h \parallel\to\infty\)</span>. En la parametrización mostrada en la Figura @ref(fig:figSemivariogramas), el parámetro <span class="math inline">\(R\)</span> es el rango práctico del semivariograma. Frecuentemente el modelo puede encontrarse en una parametrización donde el exponente es <span class="math inline">\(-\parallel h \parallel / R\)</span>. Entonces el <span class="math inline">\(R_p\)</span> corresponde a <span class="math inline">\(3R\)</span>. Para el mismo rango y meseta de un modelo esférico, el modelo exponencial alcanza el rango más rápidamente, es decir, a menor distancia que el modelo esférico. El modelo gaussiano exhibe un comportamiento cuadrático cerca del origen y produce una correlación de corto rango que son las más altas que para cualquier modelo estacionario de segundo grado con el mismo rango práctico. Además, es el más continuo cerca del origen de los considerados aquí. En la parametrización el rango práctico es <span class="math inline">\(\sqrt{3R}\)</span>.</p>
<p>Es importante notar que, si se realiza un análisis basado en semivariogramas y se pretende comparar los parámetros de los semivariogramas obtenidos bajo distintas condiciones, la utilización de modelos teóricos diferentes resulta poco útil. Hay que tener en cuenta que, por ejemplo, los rangos del modelo esférico y el exponencial no son directamente comparables. El modelo esférico es el único que tiene un umbral verdadero, ya que tanto el modelo exponencial como el gaussiano alcanzan el umbral de forma asintótica, o lo que es lo mismo, no lo alcanzan nunca y el modelo lineal no tiene umbral. En consecuencia, los rangos no son directamente equivalentes entre modelos. En este caso, es más conveniente elegir un único modelo para realizar comparaciones de procesos espaciales.</p>
<p>Los modelos de semivariograma son no lineales a excepción del modelo nugget. Por ello, para la estimación de parámetros estas funciones se usan métodos basados en aproximaciones numéricas. El método de ajuste por mínimos cuadrados ponderados (WLS) es común en la práctica. Para ello, se elige una función y valores iniciales de los parámetros basados en la observación del semivariogramas empírico. El tamaño del conjunto de datos a partir del cual el modelo de semivariograma es ajustado depende del número de <em>lags</em> que se elija. Los valores de las clases de <em>lag</em> en las cuál el número de pares no es mayor a 30 debieran ser removidos si se ajusta el semivariograma por mínimos cuadrados. Journel y Huijbregts 1978 recomiendan solo usar <em>lags</em> menores a la mitad del máximo <em>lag</em> en el conjunto de datos. La distribución de los puntos en el espacio determinará para qué <em>lags</em> esto es posible.</p>
</section></section><section id="correlación-espacial-bivariada" class="level2" data-number="2.2"><h2 data-number="2.2" class="anchored" data-anchor-id="correlación-espacial-bivariada">
<span class="header-section-number">2.2</span> Correlación espacial bivariada</h2>
<section id="coeficiente-de-correlación" class="level3" data-number="2.2.1"><h3 data-number="2.2.1" class="anchored" data-anchor-id="coeficiente-de-correlación">
<span class="header-section-number">2.2.1</span> Coeficiente de correlación</h3>
<p>El coeficiente de correlación lineal de Pearson (<span class="math inline">\(r\)</span>) es una medida de la magnitud de la correlación lineal entre dos variables. Para calcularlo se supone que se tiene una muestra aleatoria de unidades de análisis donde se han registrado simultáneamente dos variables. El intervalo de confianza para <span class="math inline">\(r\)</span> y el valor <span class="math inline">\(p\)</span> usados para decidir si la correlación poblacional entre ambas variables es cero o distinta de cero, dependen del tamaño de la muestra <span class="math inline">\(n\)</span>. El tamaño de la muestra es el número de unidades de análisis independientes.</p>
<p>Cuando las variables en estudio exhiben autocorrelación espacial, las observaciones de cada una de éstas estarán correlacionadas dentro de un determinado vecindario, es decir, no serán independientes entre sí. Luego, en el caso de datos espaciales, se viola la suposición de observaciones independientes para la prueba de significancia <span class="math inline">\(r\)</span>. Una propuesta para contemplar las correlaciones generadas por patrones espaciales es calcular el coeficiente de correlación haciendo un ajuste para determinar el número de observaciones independientes (tamaño de muestra efectivo) para acompañar la inferencia necesaria.</p>
<p>El coeficiente de correlación modificado <span class="citation" data-cites="Clifford_Richardson_Hemon_1989 Dutilleul_Clifford_Richardson_Hemon_1993">(<a href="referencias.html#ref-Clifford_Richardson_Hemon_1989" role="doc-biblioref">Clifford, Richardson, y Hemon 1989</a>; <a href="referencias.html#ref-Dutilleul_Clifford_Richardson_Hemon_1993" role="doc-biblioref">Dutilleul et&nbsp;al. 1993</a>)</span>, permite evaluar correlación entre dos variables espacializadas en el mismo dominio espacial. La prueba se basa en la modificación de las varianzas y los grados de libertad de la prueba <span class="math inline">\(t\)</span> estándar usada para evaluar significancia del coeficiente de correlación de Pearson y requiere de la estimación del tamaño efectivo de la muestra.</p>
<p>Considerando <span class="math inline">\(A \subset D\)</span> un grupo de <span class="math inline">\(n\)</span> sitios <span class="math inline">\(A={s_1, s_2,…,s_n}\)</span>, se supone que <span class="math inline">\(Z=Z(s_1), Z(s_2),…, Z(s_n)\)</span> y <span class="math inline">\(Y= Y(s_1), Y(s_2),…,Y(s_n)\)</span> con media constante y matriz de varianzas y covarianzas <span class="math inline">\(\Sigma_Z\)</span> y <span class="math inline">\(\Sigma_Y\)</span>. Se divide <span class="math inline">\(D\)</span> en los estratos <span class="math inline">\(D_0, D_1, D_2,…\)</span>. Entonces <span class="math inline">\(Cov(Z(s_i),Z(s_j))= C_Z(k)\)</span> y <span class="math inline">\(Cov\big(Y(s_i),Y(s_j)\big)= C_Y(k)\)</span>, con <span class="math inline">\(s_i, s_j \in D_k\)</span>, para <span class="math inline">\(k= 0,1,…\)</span> <span class="citation" data-cites="Clifford_Richardson_Hemon_1989">(<a href="referencias.html#ref-Clifford_Richardson_Hemon_1989" role="doc-biblioref">Clifford, Richardson, y Hemon 1989</a>)</span> sugieren como estimador de <span class="math inline">\(\hat{C}_Y(h)\)</span></p>
<p><span class="math display">\[ \hat{C}_Y(h) = \frac{\sum_{s_i,s_j \in A_k}{\big( Y(s_i) - \overline{Y} \big) \big( Y(s_j) - \overline{Y} \big)}} {n_k} \]</span></p>
<p>donde <span class="math inline">\(n_k\)</span> es la cardinalidad de <span class="math inline">\(D_k\)</span> y y similaridad para <span class="math inline">\(C_Z(k)\)</span>. Luego, <span class="citation" data-cites="Clifford_Richardson_Hemon_1989">Clifford, Richardson, y Hemon (<a href="referencias.html#ref-Clifford_Richardson_Hemon_1989" role="doc-biblioref">1989</a>)</span> sugirió utilizar <span class="math inline">\(n^{-2}\sum_h{n_h\hat{C}_Z(h) \hat{C}_Y(h)}\)</span> Como un estimador de la varianza condicional de <span class="math inline">\(s_{ZY}=n^{-1} \sum_D{ \big(Z(s)-\overline{Z} \big) \big(Y(s)-\overline{Y} \big) }\)</span>. Como resultado se obtiene la prueba <span class="math inline">\(t\)</span> modificada basada en el estadístico <span class="math inline">\(W\)</span></p>
<p><span class="math display">\[W=n \; s_{ZY} \Big( \sum_h{n_h \hat{C}_Z(h) \hat{C}_Y(h)} \Big)^{-2}\]</span></p>
<p>El cual a partir de una serie de aproximaciones a la varianza del coeficiente de correlación de Pearson (<span class="math inline">\(\sigma_r^2\)</span>) entre los procesos <span class="math inline">\(Z(s)\)</span> e <span class="math inline">\(Y(s)\)</span> se puede escribir de la siguiente manera <span class="math inline">\(W=(\hat{M}-1)^{1/2}r\)</span>, <span class="math inline">\(\hat{M} = 1 + {\hat{\sigma}}_r^{-2}\)</span> y <span class="math inline">\(\hat{\sigma}_r^2 = \frac{\sum_h{n_h \hat{C}_Z(h) \hat{C}_Y(h)}} {n^2 s_Z^2 s_Y^2}\)</span>.</p>
<p>Se define <span class="math inline">\(W\)</span> como una prueba t modificada con <span class="math inline">\(\hat{M}-2\)</span> grados de libertad, donde <span class="math inline">\(\hat{M}\)</span> es el tamaño de muestra efectivo asumiendo bajo hipótesis nula la no correlación entre <span class="math inline">\(Z(s)\)</span> e <span class="math inline">\(Y(s)\)</span>. Cuando se presenta una estructura de correlación espacial positiva, generalmente <span class="math inline">\(\hat{M} &lt; n\)</span>, si existe estructura de autocorrelación negativa se espera que <span class="math inline">\(\hat{M} &gt; n\)</span>.</p>
</section><section id="coeficiente-de-co-dispersión" class="level3" data-number="2.2.2"><h3 data-number="2.2.2" class="anchored" data-anchor-id="coeficiente-de-co-dispersión">
<span class="header-section-number">2.2.2</span> Coeficiente de co-dispersión</h3>
<p>Otra forma usada en estadística espacial para explorar patrones de correlaciones o covariaciones entre dos variables espacializadas, es el coeficiente de co-dispersión, que cuantifica la correlación entre dos procesos espaciales para un lag espacial particular sobre un espacio bidimensional. Para dos procesos espaciales intrínsecamente estacionarios <span class="math inline">\({Z(s):s\in D\subset R^2}\)</span> y <span class="math inline">\({Y(s):s\in D\subset R^2}\)</span> definidos en una parte de la región <span class="math inline">\(D\subset R^2\)</span>, el coeficiente de co-dispersión es definido como:</p>
<p><span class="math display">\[\rho_{ZY}(h)= \frac{E \Big[ \big(Z(s+h)-Z(s) \big) \big(Y(s+h)-Y(s) \big) \Big]}{\sqrt{E \big[Z(s+h)-Z(s) \big]^2 E \big[Y(s+h)-Y(s) \big]^2}}\]</span></p>
<p>La estructura de <span class="math inline">\(\rho_{ZY}\)</span> es computacionalmente similar al coeficiente de correlación de Pearson. Al igual que ese coeficiente, <span class="math inline">\(\rho_{ZY}(h)\)</span>, donde los límites superior e inferior definen una asociación espacial negativa o positiva perfecta, respectivamente. Sin embardo, a diferencia del coeficiente de correlación de Pearson, <span class="math inline">\(\rho_{ZY}\)</span> depende del lag <span class="math inline">\(h\)</span>, que enfatiza la idea de que la correlación espacial es un valor asociado con una distancia en el plano. El cálculo de la correlación se realiza para diferentes distancias y direcciones en el espacio. Cuando el coeficiente de co-dispersión se calcula para muchas direcciones, es útil mostrar esos valores en un solo gráfico. <span class="citation" data-cites="Vallejos2015">Vallejos et&nbsp;al. (<a href="referencias.html#ref-Vallejos2015" role="doc-biblioref">2015</a>)</span> proponen el mapa de co-dispersión para resumir en un plano los valores de los coeficientes de co-dispersión obtenidos para distintos <em>lag</em> espaciales (direcciones y distancias). El gráfico resume la información sobre la correlación entre dos procesos espaciales en forma radial sobre un plano que circunscribe los coeficientes en una semiesfera de radio no mayor al rango del proceso espacial @ref(fig:figGrafCoDisp). En general las correlaciones espaciales que se observan desde un gráfico de co-dispersión permanecen ocultas en el análisis exploratorio usual y pueden ser distintas a las correlaciones lineales de Pearson no restringidas espacialmente. El gráfico de co-dispersión no debe ser confundido con un mapeo de la co-dispersión de las variables en el espacio de interés. No captura similitudes relacionadas con los patrones o formas que están presentes en los procesos espaciales, sino que captura la dependencia espacial entre los procesos para una distancia h. Los ejes del gráfico de co-dispersión hacen referencia a los <em>lag</em> y direcciones y no a las coordenadas de los sitios muestrales originales.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="figuras/codispersion.jpg" class="img-fluid figure-img" width="480"></p>
<p></p><figcaption class="figure-caption">Gráfico de co-dispersión mostrando la correlación espacial entre dos variables para varios lag espaciales.</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section></section><section id="interpolación-kriging" class="level2" data-number="2.3"><h2 data-number="2.3" class="anchored" data-anchor-id="interpolación-kriging">
<span class="header-section-number">2.3</span> Interpolación Kriging</h2>
<p>La predicción espacial, es decir la predicción de valores de la variable en sitios del campo espacial donde no existen observaciones, usualmente se hace por el método kriging basándose en el semivariograma ajustado. Kriging proporciona el mejor estimador lineal insesgado del valor esperado para el sitio y un error de estimación conocido como varianza kriging. Esta varianza depende del modelo de semivariograma ajustado y de la ubicación en el espacio de los datos observados ya que son los datos observados en distintos sitios los que proveen información para aproximar el valor en el sitio sin dato. Las interpolaciones basadas en semivariograma, se denominan geoestadísticas y tienen ciertas ventajas respecto a interpolaciones determinísticas, como las obtenidas por el método IDW que se basa en las distancias geométricas entre los sitios con datos y el sitio a interpolar. Las observaciones que participan en la predicción se ponderan de forma distinta según la distancia estadística a la que se encuentran.</p>
<p>Los parámetros del semivariograma son los que gobiernan la asignación de los pesos o ponderaciones de las observaciones vecinas al sitio al cual se le asignará la predicción. El parámetro <em>nugget</em> es determinante en la asignación de pesos. si la varianza del error es muy alta, todas las observaciones tenderán a tener el mismo peso en la interpolación. Por el contrario, si la varianza del error es baja, los coeficientes de ponderación serán distintos. Si el rango aumenta, cada punto tendrá mayor peso en la interpolación de otras observaciones. Entre los métodos de interpolación geoestadísticos que utilizan todos los datos simultáneamente se destacan los métodos de kriging ordinario, simple y universal. En el kriging ordinario la media de la variable es estimada localmente. En caso de conocer la media poblacional de la variable, hecho que raramente ocurre, se utiliza el kriging simple. En el kriging universal se estima también la influencia de una tendencia espacial de los datos. La predicción asignada a los puntos incógnita puede realizarse de manera puntual (kriging puntual) o definiendo bloques (kriging en bloques) <span class="citation" data-cites="Schabenberger_Gotway_2005 Webster_Oliver_2007">(<a href="referencias.html#ref-Schabenberger_Gotway_2005" role="doc-biblioref">Schabenberger y Gotway 2005</a>; <a href="referencias.html#ref-Webster_Oliver_2007" role="doc-biblioref">Webster y Oliver 2007</a>)</span>.</p>
<section id="kriging-ordinario" class="level3" data-number="2.3.1"><h3 data-number="2.3.1" class="anchored" data-anchor-id="kriging-ordinario">
<span class="header-section-number">2.3.1</span> Kriging ordinario</h3>
<p>El kriging ordinario supone que la variación es aleatoria, que existe dependencia espacial y que el proceso espacial subyacente es intrínsecamente estacionario con media constante y varianza que depende solo de la separación en distancia entre los sitios y no de su posición. La predicción kriging resulta de una combinación lineal de los datos observados. Supongamos que los valores de <span class="math inline">\(Z\)</span>, han sido muestreados en los puntos <span class="math inline">\(s_1{,s}_2,\ldots,s_n\)</span>, para generar N datos <span class="math inline">\(z(s_i),\ i=1,\ 2,\ldots, N\)</span>. Para el caso del kriging ordinario puntual se predice <span class="math inline">\(Z\)</span> en cualquier nuevo punto <span class="math inline">\(s_0\)</span> mediante:</p>
<p><span class="math display">\[\hat{Z}(s_0)=\sum_{i=1}^{N}{w_iz(s_i)}\]</span></p>
<p>donde <span class="math inline">\(w\)</span> son los pesos asignados a cada observación. Para asegurar que la estimación del valor esperado para el sitio sea insesgada y de mínima varianza, los pesos son dado de manera que:</p>
<p><span class="math display">\[\sum_{i = 1}^{N}{w_i=1}\]</span></p>
<p><span class="math display">\[E\big[\hat{Z}(s_0)-z(s_0)\big]=0\]</span></p>
<p><span class="math display">\[\begin{align*}
Var\big[\hat{Z}(s_0) \big] &amp; = E\big[\hat{Z}(s_0) - z(s_0)^2 \big] \\&amp;= 2\sum_{i=1}^{N}{w_i\gamma(s_i-s_0)-\sum_{i=1}^{N}\sum_{j=1}^{N}{w_iw_j\gamma(s_i-s_j)}}
\end{align*}\]</span></p>
<p>donde la cantidad <span class="math inline">\(\gamma(s_i - s_0)\)</span> es la semivarianza de <span class="math inline">\(Z\)</span> entre el punto de muestreo <span class="math inline">\(i\)</span> y el punto objetivo <span class="math inline">\(x_0\)</span> y <span class="math inline">\(\gamma(s_i - s_j)\)</span> es la semivariancia entre los puntos de muestreo <span class="math inline">\(i\)</span> y <span class="math inline">\(j\)</span>. Las semivarianzas se derivan del modelo teórico de semivariograma, debido a que no hay existen valores de semivarianzas entre los sitios con datos y los sitios objetivos donde no existen valores observados. Si un sitio objetivo también es un punto de muestreo, el kriging puntual devuelve el valor observado en ese sitio y la varianza de estimación es cero. El kriging puntual es un interpolador exacto en este sentido. El siguiente paso en kriging es encontrar los pesos que minimizan la varianza de la predicción sujeto a la restricción de que la suman de los pesos se igual a 1.</p>
<p><span class="math display">\[\sum_{i=1}^{N}w_i\gamma(s_i-s_0)+\psi(s_0)=\gamma(s_j-s_0) \forall j\]</span></p>
<p>La cantidad <span class="math inline">\(\psi (s_0)\)</span> es el multiplicador de Lagrange introducido para lograr la minimización. La solución de las ecuaciones de kriging proporciona los pesos para las ponderaciones y la varianza de predicción se obtiene de la siguiente forma:</p>
<p><span class="math display">\[\sigma^2(s_0)=\sum_{i=1}^{N}{w_i\gamma(}s_i-s_0)+\ \psi(s_0)\]</span></p>
</section><section id="kriging-en-bloques" class="level3" data-number="2.3.2"><h3 data-number="2.3.2" class="anchored" data-anchor-id="kriging-en-bloques">
<span class="header-section-number">2.3.2</span> Kriging en bloques</h3>
<p>El kriging en bloques consiste en estimar directamente el valor promedio de la variable sobre un soporte mayor que el soporte de los datos (bloque). Intuitivamente, la idea es calcular mediante kriging puntual los valores en todos los puntos de una superficie o bloque y usar la media de las predicciones como estimador del valor esperado para el sitio. La estimación para cualquier bloque sigue siendo un promedio ponderado de los datos, <span class="math inline">\(z\ (s_1),\ z\ (s_2),\ ...,\ z\ (s_N)\)</span>:</p>
<p><span class="math display">\[\hat{Z}(B)=\sum_{i=1}^{N}{w_iz(s_i)}\]</span></p>
<p>Los factores de ponderación se obtienen nuevamente para minimizar la varianza del error y para obtener un estimador insesgado de la media. La grilla de predicción sobre la que se construye el mapa de variabilidad espacial presenta una dimensión menor que la de los bloques, asegurándose la obtención de un mapa más suavizado respecto al obtenido con kriging puntual. El kriging en bloques ha mostrado ser efectivo a la hora de reducir errores que pueden trasladarse en los mapas como consecuencia de inexactitudes de datos puntuales.</p>
</section><section id="kriging-local" class="level3" data-number="2.3.3"><h3 data-number="2.3.3" class="anchored" data-anchor-id="kriging-local">
<span class="header-section-number">2.3.3</span> Kriging local</h3>
<p>Hemos dicho que los pesos de las observaciones en la predicción geoestadística son funciones de las semivarianzas entre las observaciones en sitios en el vecindario, <span class="math inline">\(\gamma(s_i-s_j)\)</span>, y entre cada punto de muestreo y el punto a predecir, <span class="math inline">\(\gamma(s_i-s_0)\)</span>. En general solo los puntos cercanos al punto a predecir tienen un peso significativo. Cuando la relación nugget:sill es pequeña el interpolador kriging es visto como un predictor local, donde para la predicción de <span class="math inline">\(Z(s_0)\)</span> participarán sólo datos de puntos dentro de la proximidad de <span class="math inline">\(s_0\)</span> (<em>kriging neighborhood</em> o kriging local). El kriging local esencialmente asigna pesos <span class="math inline">\(w(s_0)=0\)</span> para todos los puntos <span class="math inline">\(s_i\)</span> fuera de la zona en la que se quiere predecir. Por otra parte, esto permite que podemos aceptar el supuesto de estacionariedad local (o cuasi estacionariedad), es decir se puede restringir el supuesto de estacionariedad de la media a los vecindarios del kriging. Lo que sucede en distancias mayores a las del vecindario del sitio no será de importancia para la predicción en el sitio. La predicción y varianza kriging dependen principalmente de la parte del semivariograma cercana al origen, por ello es de importancia modelar bien el semivariograma en estos lugares, <em>i.e.</em> dar más peso a las semivarianzas experimentales cercanas al origen. No hay reglas para definir el vecindario para implementar el kriging local, aunque cuando el nugget es relativamente bajo se pude definir un radio de vecindad cercano al rango o rango práctico del modelo de semivariograma ajustado. Cuando el efecto nugget es importante el radio de vecindad debería ser mayor al rango ya que es probable que puntos más distantes tengan aún peso significativo. Otra alternativa para definir el vecindario se basa en términos de un número mínimo y máximo de datos cercanos al punto a predecir. Algunos autores recomiendan utilizar un mínimo de 7 vecinos y un máximo de 20.</p>
</section><section id="kriging-universal" class="level3" data-number="2.3.4"><h3 data-number="2.3.4" class="anchored" data-anchor-id="kriging-universal">
<span class="header-section-number">2.3.4</span> Kriging universal</h3>
<p>La suposición de estacionariedad intrínseca no se cumple cuando existen tendencias geográficas pronunciada de naturaleza sistemática y no aleatoria. La tendencia puede ser regional, es decir, una variación sistemática en toda la región de interés o local de un punto a otro dentro de la región estudiada. La existencia de tendencias puede ser explorada graficando los datos de la variable analizada en función a la variable que se supone genera la tendencia espacial. La tendencia también se manifiesta en los semivariogramas experimentales con un incremento de la semivarianza con la distancia que no tiene límites. Si hay tendencia, entonces <span class="math inline">\(\mu\)</span> ya no es constante, sino que depende de s. Además, el semivariograma experimental de los datos ya no estima el semivariograma de los errores aleatorios, <span class="math inline">\(\varepsilon(s)\)</span>. Se necesita estimar el semivariograma de <span class="math inline">\(\varepsilon(s) = Z (s) - \mu(s)\)</span>. Cuando este variograma es el input del kriging, el proceso de interpolación se conoce como “kriging universal” y la predicción se obtiene como:</p>
<p><span class="math display">\[\hat{Z}(s_0)=\sum_{i=1}^{N}{w_i \; f_kz(s_i)}\]</span></p>
<p>donde <span class="math inline">\(f_k\)</span> es función de las coordenadas espaciales.</p>
</section><section id="validación-cruzada" class="level3" data-number="2.3.5"><h3 data-number="2.3.5" class="anchored" data-anchor-id="validación-cruzada">
<span class="header-section-number">2.3.5</span> Validación cruzada</h3>
<p>La predicción implica asignar nuevos valores de las variables respuesta a contextos o escenarios que no corresponden al conjunto de escenarios medidos, es decir no se trata de aquellos sitios que utilizaron para realizar la predicción espacial. Entre las alternativas para estimar la exactitud de la predicción existen las técnicas de validación cruzada o técnicas de partición del conjunto de datos en datos de calibración y datos de validación <span class="citation" data-cites="Efron_Hastie_2016">(<a href="referencias.html#ref-Efron_Hastie_2016" role="doc-biblioref">Efron y Hastie 2016</a>)</span>. Es necesario identificar un grupo de observaciones sobre las que se ajustará el modelo o el método que permite predecir, usualmente llamado datos de calibración, y otro grupo que se usará para validar, llamado datos de validación. El modelo (semivariograma teórico) se ajusta sobre el conjunto de datos de entrenamiento y posteriormente se usa para la predicción de interés, con observaciones del subconjunto de validación. Seguidamente, los valores observados del conjunto de validación se comparar con los valores predichos por el modelo. Usualmente el proceso se repite cruzando el rol de los subconjuntos de datos, es decir el que era de validación pasa a ser de calibración y viceversa.</p>
<p>Sin embargo, otras estrategias pueden ser usadas para la selección de los datos de entrenamiento y validación. Una es particionar en forma aleatoria los datos en ambos conjuntos. Otro tipo de validación cruzada es dejando uno fuera (<em>Leave-One-Out</em>) donde se utiliza una sola observación para conformar el subconjunto de validación y se deja al resto como subconjunto de entrenamiento. El modelo se ajusta utilizando las <span class="math inline">\(n – 1\)</span> observaciones de entrenamiento y se obtiene una predicción para la observación excluida. Este proceso se repite <span class="math inline">\(n\)</span> veces. Otro tipo de validación cruzada es <span class="math inline">\(k-fold\)</span>, donde las observaciones se dividen aleatoriamente en <span class="math inline">\(k\)</span> grupos de aproximadamente igual tamaño. Uno de los <span class="math inline">\(k\)</span> grupos se emplea como subconjunto de validación, mientras que el resto de los grupos se emplean para entrenar el modelo. El proceso de validación cruzada es repetido durante k iteraciones, con cada uno de los subconjuntos de datos de prueba. Un valor común de <span class="math inline">\(k\)</span> que puede dar buenos resultados en cuanto al equilibrio sesgo-varianza para estimar el error de predicción es <span class="math inline">\(k=10\)</span>. Si el modelo tuvo un buen desempeño, los residuos de la validación cruzada serán pequeños, su media será cercana a cero y no presentarán estructura.</p>
<p>En la evaluación de modelos geoestadísticos, los valores predichos de kriging <span class="math inline">\(\hat{Z}(s_i)\)</span> se comparan con los observados <span class="math inline">\(z(s_i)\)</span>, y se calcula una medida resumen que caracteriza el resultado de la comparación. Algunas de estas medidas resumen son:</p>
<p>Error medio</p>
<p><span class="math display">\[ME=\frac{1}{N}\sum_{i=1}^{N}\big\{z(s_i)-\hat{Z}(s_i)\big\}\]</span></p>
<p>donde <span class="math inline">\(N\)</span> es el número de observaciones, <span class="math inline">\(z(s_i)\)</span> es el valor verdadero en <span class="math inline">\(s_i\)</span> y <span class="math inline">\(\hat{Z}(s_i)\)</span> es el valor predicho en ese punto.</p>
<p>Error cuadrático medio (Mean Square Error, MSE):</p>
<p><span class="math display">\[MSE=\frac{1}{N}\sum_{i=1}^{N}{\big\{z(s_i)-\hat{Z}(s_i)\big\}^2}\]</span></p>
<p>Raíz del error cuadrático medio:</p>
<p><span class="math display">\[RMSE=\frac{1}{N}\sqrt{\sum_{i=1}^{N}\big\{z(s_i)-\hat{Z}(s_i)\big\}^2}\]</span></p>
<p>Media del cociente del error cuadrático (Mean Squared Deviation Ratio, MSDR):</p>
<p><span class="math display">\[MSDR=\frac{1}{N} \sum_{i=1}^{N}\frac{ \big\{ z(s_i) - \hat{Z}(s_i) \big\}^2} {\hat{\sigma}^2(s_i)}\]</span></p>
<p>donde <span class="math inline">\(\hat{\sigma}^2(s_i)\)</span> es la varianza de la predicción kriging en el punto <span class="math inline">\(s_i\)</span>.</p>
<p>Para el caso de datos espaciales, no solo es necesario disponer de una medida de error de predicción global, sino que también hay que evaluar del error de la predicción en cada sitio específico, <em>i.e.</em> dimensionar el error puntual de la predicción espacial.</p>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography" style="display: none">
<div id="ref-Babai_1979" class="csl-entry" role="doc-biblioentry">
Babai, László. 1979. <span>«Monte-Carlo algorithms in graph isomorphism testing»</span>. <em>Université tde Montréal Technical Report, DMS</em>, n.º 79–10.
</div>
<div id="ref-Clifford_Richardson_Hemon_1989" class="csl-entry" role="doc-biblioentry">
Clifford, Peter, Sylvia Richardson, y Denis Hemon. 1989. <span>«Assessing the Significance of the Correlation between Two Spatial Processes»</span>. <em>Biometrics</em> 45 (1): 123-34. <a href="https://doi.org/10.2307/2532039">https://doi.org/10.2307/2532039</a>.
</div>
<div id="ref-Dutilleul_Clifford_Richardson_Hemon_1993" class="csl-entry" role="doc-biblioentry">
Dutilleul, Pierre, Peter Clifford, Sylvia Richardson, y Denis Hemon. 1993. <span>«<span>Modifying the t Test for Assessing the Correlation Between Two Spatial Processes</span>»</span>. <em>Biometrics</em> 49 (1): 305. <a href="https://doi.org/10.2307/2532625">https://doi.org/10.2307/2532625</a>.
</div>
<div id="ref-Efron_Hastie_2016" class="csl-entry" role="doc-biblioentry">
Efron, Bradley, y Trevor Hastie. 2016. <em>Computer age statistical inference: Algorithms, evidence, and data science</em>. <em>Computer Age Statistical Inference: Algorithms, Evidence, and Data Science</em>. <a href="https://doi.org/10.1017/CBO9781316576533">https://doi.org/10.1017/CBO9781316576533</a>.
</div>
<div id="ref-Schabenberger_Gotway_2005" class="csl-entry" role="doc-biblioentry">
Schabenberger, Oliver, y Carol A Gotway. 2005. <em>Statistical methods for spatial data analysis</em>. CRC press.
</div>
<div id="ref-Vallejos2015" class="csl-entry" role="doc-biblioentry">
Vallejos, Ronny, Adriana Mallea, Myriam Herrera, y Silvia Ojeda. 2015. <span>«A multivariate geostatistical approach for landscape classification from remotely sensed image data»</span>. <em>Stochastic Environmental Research and Risk Assessment</em> 29 (2): 369-78. <a href="https://doi.org/10.1007/s00477-014-0884-5">https://doi.org/10.1007/s00477-014-0884-5</a>.
</div>
<div id="ref-Webster_Oliver_2007" class="csl-entry" role="doc-biblioentry">
Webster, Richard, y Margaret A Oliver. 2007. <em>Geostatistics for environmental scientists</em>. <em>Vadose Zone Journal</em>. Vol. 1. 2. John Wiley &amp; Sons. <a href="https://doi.org/10.2136/vzj2002.0321">https://doi.org/10.2136/vzj2002.0321</a>.
</div>
<div id="ref-Zimback_2001" class="csl-entry" role="doc-biblioentry">
Zimback, C R L. 2001. <span>«Análise espacial de atributos químicos de solos para fins de mapeamento da fertilidade do solo. 2001. 114 f»</span>.
</div>
</div>
</section></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiado");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiado");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./Parte1_cap_a_MjoDtosEsp.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Manejo de datos espaciales</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./Parte1_cap_c_CarcVarEspMultiCapa.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Caracterización de variabilidad espacial con múltiples capas de datos</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Ejecutar el código</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Caracterización de variabilidad espacial</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: "asis"</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">"_common.R"</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>Denotamos el proceso espacial en $d$ dimensiones como: ${Z(s): s\in\ D\subset R^d}$ donde $Z$ denota el atributo que observamos, $s$ es la ubicación en la cual $Z$ es observada y es un vector de coordenadas de dimensiones $n\times2$  y $D$ es el dominio. Los procesos espaciales que se abordarán en este libro son procesos bidimensionales, $d=2$ y $s=x,y \prime$ son tratadas como coordenadas cartesianas. Cuando la $d$ es mayor a 1, el proceso estocástico subyacente es definido como un campo aleatorio.</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>La colección de n observaciones georreferenciadas que conforman un conjunto de datos espaciales deben entenderse como una muestra de tamaño uno de una distribución n-dimensional. En este caso la $E\left<span class="co">[</span><span class="ot">Z(s)\right</span><span class="co">]</span>=\mu(s)$ representa el promedio del atributo en la ubicación $s$ sobre la distribución de una posible realización. Si quisiéramos determinar el valor esperado para un sitio no observado, para $s_0$, sería necesario repetir las observaciones en ese punto, pero usualmente solo se tiene una observación por sitio. Sólo se puede hacer inferencia basada en una muestra de tamaño uno, bajo condiciones de estacionaridad, es decir cuando la esperanza es la misma en todos los puntos. Por ello, un supuesto importante para el análisis de los datos espaciales será el de estacionaridad. Bajo estas condiciones la variabilidad espacial podrá ser caracterizada a través de funciones basadas solo en varianzas y covarianzas o autocorrelaciones en los datos espaciales.</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>La autocorrelación espacial mide la correlación lineal entre los valores de una variable aleatoria y los de otra construida a partir del rezago de la primera. Puede interpretarse como medida de la coincidencia de valores similares de una variable en espacios geográficos cercanos, es decir, la variable tiende a asumir valores similares en unidades geográficamente cercanas. Mediado por la distancia, queremos saber qué tan semejante o diferente es el valor de la variable "consigo misma". Luego, para una variable espacialmente autocorrelacionada, los valores observados en el espacio no serán aleatorios, sino que estarán espacialmente relacionados.</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>La autocorrelación puede ser global o local. El primer tipo considera los valores de todas las observaciones, mientras el segundo solo los valores de las observaciones de un sitio respecto a los de observaciones vecinas. En ambos casos, la autocorrelación espacial puede ser medida en términos de su intensidad; una autocorrelación espacial fuerte significa que los valores del atributo de las unidades de observación geográfica vecinas muy parecidos o predecibles desde el valor del sitio, el caso contrario se produce cuando la distribución en sitios vecinos refleja un patrón aleatorio. El análisis de autocorrelación espacial requiere contar con una medida de correlación lineal apropiada para medir grados de semejanza entre las observaciones en un sitio y en su entorno.</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>Los índices de autocorrelación espacial expresan de manera formal el grado de correlación lineal entre las variables aleatorias representadas funcionalmente por el vector de valores observados y el vector de medias ponderadas espacialmente en las unidades vecinas, llamado el vector con *lag espacial*. El cálculo de estos índices en un espacio continuo requiere la definición de una matriz de ponderación espacial. Ésta puede tener elementos binarios para indicar cuáles son las observaciones que pertenecen al vecindario de cada dato, *i.e.* las observaciones "conectadas" con cada dato.</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>También puede tener como elementos, los valores de un coeficiente de continuidad que mide el grado de conexión entre un par de datos. El elemento $w_{ij}$ de la matriz de ponderaciones $W$, es el peso aplicado a la comparación de las observaciones en la posición $i$ y la posición $j$. Usualmente se utilizan redes de conexión que derivan en un matriz de pesos espaciales. La red de vecindarios también puede ser definida considerando puntos vecinos a aquellos contiguos ubicados entre un límite inferior y superior, previamente preestablecido. Cuando las entidades se encuentran distribuidas en forma homogénea en el espacio, suele recomendarse la red de conexión obtenida por el método de triangulación de Delaunay Las redes de conexión también pueden ser adaptadas manualmente pudiéndose excluir contactos entre sitios cercanos o incluir relaciones entre sitios lejanos.</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>Por ejemplo, el índice de autocorrelación espacial de Geary (GI), expresa la magnitud de las desviaciones entre observaciones en diferentes localizaciones. Siendo $w..$ la suma de todos los pesos, la expresión del índice es:</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>$$GI=\frac{(n-1)\sum_{i}\sum_{j}{w_{ij}(Z(s_i)\ -\ Z(s_j))^2}}{2w..\sum_{i}{(Z(s_i)-\bar{z})}^2}$$</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>El valor de GI se encuentra en el intervalo <span class="co">[</span><span class="ot">0,2</span><span class="co">]</span>. Si no hay autocorrelación espacial, el valor esperado de GI es 1. Valores del índice entre 1 y 2 indican autocorrelación espacial negativa, y entre 0 y 1 autocorrelación espacial positiva. Este índice se relaciona inversamente con el índice MI, es decir valores más cercanos a 0 sugieren autocorrelaciones positivas más fuerte. GI es más sensible a pequeñas diferencias entre posiciones vecinas que el IM. Los índices de autocorrelación espacial local son calculados para cada sitio y usan solo ponderadores para las distancias entre las observaciones de ese sitio y las restantes. El índice LM fue descripto anteriormente para ejemplificar su uso en la detección de *outliers*. Otro índice de autocorrelación espacial local es el índice de Getis Ord (GO) el que se calcula como la suma de los valores observados para la $j-ésima$ variable en el vecindario centrado del $i-ésimo$ píxel, en relación con la suma de todas las observaciones. Su expresión estandarizada es:</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>$${GO}_i=\frac{\sum_{i=1}^{m}{w_{i,i^\prime}{Z(s}_{i^\prime})-\bar{Z}\sum_{i=1}^{m}w_{i,i^\prime}}}{S\sqrt{\frac{m\sum_{i=1}^{m}{w_{i\neq i^\prime}^2-\left(\sum_{i=1}^{m}w_{i\neq i^\prime}\right)^2}}{n-1}}}$$</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>donde $w_i$ representa pesos espaciales en un vecindario del $i-ésimo$ píxel de tamaño $m$. Valores positivos de GO indican grupos locales de valores altos para la variable alrededor de la $i-ésima$ ubicación, mientras que valores negativos indican grupos locales de valores bajos alrededor de la $i-ésima$ ubicación. Para evaluar la significancia estadística de estos índices es posible utilizar procedimientos del tipo Monte Carlo <span class="co">[</span><span class="ot">@Babai_1979</span><span class="co">]</span>. Las ubicaciones son permutadas en el espacio para obtener la distribución del índice bajo la hipótesis nula de distribución aleatoria.</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="fu">## Semivariogramas</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>La dependencia espacial o autocorrelación espacial, puede modelarse mediante un semivariograma. Esta función permite analizar la estructura y la naturaleza de la dependencia espacial en un conjunto de observaciones geo-referenciadas. El proceso espacial puede ser representado por el siguiente modelo estadístico:</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>$$Z\left(s\right)=\mu+\varepsilon\left(s\right)$$</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>donde $\mu$ es la media del proceso y $\varepsilon\left(s\right)$ es un término de error aleatorio con media cero y covarianza $C(h)$, donde $h$ es el *lag* o separación en el espacio entre dos sitios particulares. Un campo aleatorio ${Z(s):\ s\in\ D\subset R^d}$ es estrictamente estacionario si la distribución espacial es invariante bajo traslación de las coordenadas a través de todo el dominio (estacionaridad en sentido fuerte). La estacionaridad de segundo orden, o estacionaridad en sentido débil, se produce cuando $E\left<span class="co">[</span><span class="ot">Z\left(s\right)\right</span><span class="co">]</span>=\mu\left(s\right)$ y $Cov\big<span class="co">[</span><span class="ot">Z(s),Z(s+h)\big</span><span class="co">]</span>=C(h)$. Es decir, en un campo aleatorio estacionario de segundo orden, la media es constante y la covarianza entre observaciones sobre diferentes posiciones, es función de la separación espacial entre los sitios en las que son tomadas, $C(h)$ es la función de covarianza del proceso espacial. La estacionaridad de primero orden implica la estacionaridad de segundo orden, pero la inversa no es cierta.</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>Dado que $C(h)$ no depende del valor de las coordenadas y $Cov\big<span class="co">[</span><span class="ot">Z(s),Z(s+0)\big</span><span class="co">]</span>= Var \big<span class="co">[</span><span class="ot">Z(s)\big</span><span class="co">]</span>=C$, en procesos estacionarios de segundo orden, la variabilidad es la misma en todas partes, *i.e.* $Var <span class="co">[</span><span class="ot">Z(s)</span><span class="co">]</span>=\sigma^2$ no es una función de la ubicación espacial. En síntesis, un proceso espacial estacionario de segundo orden tiene media y varianza constantes y la función de covarianza no depende en absoluto de las coordenadas. A $C\left(h\right)$ también se la conoce como función de autocovarianza y depende de la escala en la cual $Z$ fue medida. Resulta más conveniente y fácil de interpretar si se la hace adimensional convirtiéndola en autocorrelación $\rho\left(h\right)=\frac{C(h)}{C}$. La función $\rho\left(h\right)$ se denomina correlograma del proceso espacial.</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>Aún si $Z(h)$ no es estacionaria de segundo orden, el incremento $Z(s)-Z(s+h)$ puede serlo. Un proceso que tiene esta característica se dice que tiene estacionaridad intrínseca. Esto se produce si $E\big<span class="co">[</span><span class="ot">(Z(s)\big</span><span class="co">]</span>=\mu$ y $\frac{1}{2}Var\big<span class="co">[</span><span class="ot">Z(s)-Z(s+h)\big</span><span class="co">]</span>=\gamma(h)$.</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>La función $\gamma(h)$ es llamada semivariograma del proceso espacial. La clase de procesos intrínsecamente estacionario es más grande que la clase de procesos estacionarios de segundo orden  Notar que un proceso espacial que presenta estacionaridad intrínseca no es necesariamente estacionario de segundo orden. En condiciones de estacionaridad de segundo orden la función de covarianza es el semivariograma.</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>Un proceso que parece estacionario en una escala podría no serlo a otra escala (*i.e.* presentar una tendencia o un componente sistemático). En el modelo, $\mu$ será remplazado por $\mu(s)$, *i.e.* término de tendencia determinístico para el sitio $s$. El semivariograma, en estos casos se calcula sobre los residuos del modelo. El semivariograma, puede interpretarse como función de la varianza de la diferencia entre las observaciones. Si el semivariograma es sólo una función de la distancia entre observaciones, entonces es conocido como semivariograma isotrópico, *i.e.* no depende de la dirección. El semivariograma y covariograma son parámetros del proceso espacial y juegan un rol crítico en los métodos geoestadísticos de análisis de datos espaciales.</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>Un primer paso para caracterizar la variación espacial en un dominio continuo es construir un semivariograma experimental o empírico. Una fórmula usual para computar semivariogramas, es conocida como estimador de los momentos de Matheron</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>$$\hat{\gamma}(h)=\frac{1}{2 m (h)}\sum_{i=1}^{m(h)} \Big<span class="sc">\{</span>Z(s_i)-Z(s_i+h) \Big<span class="sc">\}</span>^2$$</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>donde $m(h)$ es el número de pares de puntos separados por la particular distancia $h$. El otro estimador ampliamente usado es el estimador de Cressie- Hawkins o estimador robusto cuya fórmula se expresa como</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>$$2 \widetilde{\gamma}(h)= \frac{\Big<span class="co">[</span><span class="ot"> \frac{1}{m(h)} \sum_{i=1}^{m(h)} \Big| Z(s_i) - Z(s_i + h) \Big| ^\frac{1}{2}  \Big</span><span class="co">]</span> ^4}{0,457 + \frac{0,494}{m(h)} + \frac{0,045}{m^2(h)}}$$</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>Este estimador puede ser menos sesgado que $\hat{\gamma}(h)$ cuando la varianza residual es relativamente pequeña siendo también menos sensible a la presencia de valores externos. El estimador muestra típicamente menor variación en distancias pequeñas y también resulta en valores generalmente más pequeños que el estimador de los momentos de Matheron. Computando cualquiera de los dos estimadores, para las distancias $h$, obtenemos un conjunto ordenado de semivarianzas. Tales semivarianzas graficadas en función h constituye el semivariograma empírico o experimental.</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>Los parámetros de un semivariograma son: la varianza nugget o simplemente nugget $(C_0)$, la varianza estructural o sill parcial $(C)$ y el rango $(R)$. La asíntota es llamada la meseta del semivariograma o $C$ y el lag o distancia $h^\ast$ en el cual la meseta es alcanzada se denomina $R$ o rango. Observaciones $Z(s_i)$ y $Z(s_j)$ para las cuales $|| Z(s_i) - Z(s_j)|| \geq h^\ast$ son espacialmente independientes. Si el semivariograma alcanza la meseta asintóticamente, se define el rango práctico $(R_P)$ como la distancia en el cual la semivarianza alcanza el 95\% de la varianza umbral o total.</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a><span class="in">```{r semivariogramasej, echo = FALSE, fig.cap= "a) Semivariograma empírico. b) Semivariograma teórico, modelo esférico. Se representan los tres parámetros que lo definen: rango, sill y efecto pepita o nugget."}</span></span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"figuras/semivEmpTeo.png"</span>)</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a>En la práctica el semivariograma empírico $\hat{\gamma}(h)$ puede no pasar a través del origen. La ordenada al origen del semivariograma representa a $C_{0}$, por lo tanto $C_0=\lim_{h\rightarrow0}{g(h)}\neq0$. Este parámetro representa la suma de errores aleatorios o no estructurados espacialmente, así como errores asociados con la variabilidad espacial a escalas más finas que la usada para realizar las mediciones. Un alto valor de $C_0$ indica que la mayoría de la variación espacial no es explicada por el semivariograma. La varianza umbral o sill se obtiene sumando las varianzas antes mencionadas ($C_0+C$) y es la varianza de observaciones independientes, es decir observaciones que fueron tomadas a mayor distancia que $R$.</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>Un semivariograma se define como anisotrópico si cambia en alguna forma respecto a la dirección que se considere. Si el semivariograma no solo depende de la longitud del vector h sino también de la dirección del vector entonces el semivariograma es anisotrópico. En los casos isotrópicos, los contornos de isocorrelación son esféricos, mientras que en el caso que haya anisotropía los contornos de isocorrelación son elípticos. Se reconocen dos tipos de anisotropía: anisotropía geométrica y anisotropía zonal. Anisotropía geométrica ocurre cuando el rango del semivariograma cambia en las distintas direcciones, pero no la varianza sill, por lo tanto, la correlación es más fuerte en una dirección que en otra. Anisotropía zonal existe cuando la varianza estructural del semivariograma cambia con la dirección. Anisotropía geométrica significa que la correlación es más fuerte en una dirección que en otra.</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>Una forma en que la anisotropía geométrica puede ser identificada es graficando un semivariograma experimental direccional. Diferencias en el semivariograma muestral usando diferentes ángulos al computarlo, es indicador de anisotropía. La anisotropía geométrica puede ser modelada cambiando el modelo de semivariograma por un proceso isotrópico transformando las coordenadas. Los modelos teóricos de semivariograma más usados en predicción espacial están basados son isotrópicos, por lo que es necesario una corrección en casos de anisotropía para poder utilizar la metodología clásica de predicción en geoestadística. El radio de anisotropía, es decir, el cociente entre los rangos de la dirección de máximo y mínima variación es usada para mesurar anisotropía. Algunos autores consideran que existe anisotropía significativa si el radio de anisotropía es mayor a 2,5.</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a><span class="in">```{r modeloIsoAniso, echo = FALSE, fig.cap = "a) Modelo isotrópico. b) Modelo anisotrópico, con ángulo de anisotropía de 45º y un radio de anisotropía de 0,5."}</span></span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"figuras/modeloIsoAniso.png"</span>)</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a>En los procesos espaciales continuos, caracterizados por semivariogramas suelen obtenerse medidas del grado de estructuración espacial. Una de éstas es la varianza estructural relativa (RSV):</span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a>$$RSV=\Bigg(\frac{C}{C+C_0}\Bigg)\times100\%$$</span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a>Un valor alto de RSV indica que las predicciones geoestadísticas serán más eficientes que aquellas obtenidas con métodos de predicción que ignoran la información espacial. Un valor alto de RSV también indica una continuidad mayor del proceso espacial. @Zimback_2001 establece que el grado de dependencia espacial puede ser clasificado como: $RSV \leq 25\%$ bajo, $RSV$ entre $25\%$ y $75\%$ medio y $RSV \geq 75\%$ alto. También se puede calcular el cociente $\frac{C_0}{C_0+C}$ y en función de éste hablar de estructura espacial fuerte cuando el cociente es: $\leq 25\%$, intermedia si el mismo se encuentra entre 25\% y 75\% y débil si el mismo es mayor al 75\%.</span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a><span class="fu">### Ajuste de semivariogramas</span></span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a>El semivariograma empírico $\hat{\gamma}(h)$, es un estimador insesgado de $\gamma(h)$, pero provee solo estimaciones para un conjunto finito de distancias. Para obtener estimaciones de $\gamma(h)$, para cualquier lag, al semivariograma empírico se le ajusta un modelo teórico. El análisis geoestadístico sigue entonces estos dos pasos: 1) obtención del semivariograma empírico y 2) ajuste de un modelo teórico de semivariograma al semivariograma empírico.</span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a>Las funciones que sirven como modelos teóricos de semivariograma deben ser condicionalmente definidas positivas. Existen varios modelos teóricos para funciones semivariogramas, entre los que se encuentran el modelo nugget, el lineal, el esférico, el gaussiano y el exponencial (Figura \@ref(fig:figSemivariogramas)). El semivariograma de un proceso de ruido blanco (modelo nugget), donde los valores $Z\left(s\right)$ se comportan como muestras aleatorias, todas con igual media y varianza sin correlación entre ellas. Este modelo suele ajustar el semivariograma empírico cuando la menor distancia de muestreo en los datos es mayor que el rango del proceso espacial.</span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a><span class="in">```{r figSemivariogramas, echo = FALSE, purl=FALSE, fig.cap="Funciones de semivariograma para el modelo exponencial, esférico y gaussiano. $C_0$=2, $C$=10 y $R$=200" }</span></span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"figuras/Semivariogramas.jpg"</span>)</span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a>El modelo esférico es uno de los más populares entre los modelos de semivariograma. Tiene dos características principales: un comportamiento lineal cerca del origen y el hecho de que a la distancia $R$ el semivariograma encuentra la meseta y después de esta se mantiene llano. El modelo exponencial se aproxima a la meseta del semivariograma asintóticamente cuando $\parallel h \parallel\to\infty$. En la parametrización mostrada en la Figura \@ref(fig:figSemivariogramas), el parámetro $R$ es el rango práctico del semivariograma. Frecuentemente el modelo puede encontrarse en una parametrización donde el exponente es $-\parallel h \parallel / R$. Entonces el $R_p$  corresponde a $3R$. Para el mismo rango y meseta de un modelo esférico, el modelo exponencial alcanza el rango más rápidamente, es decir, a menor distancia que el modelo esférico. El modelo gaussiano exhibe un comportamiento cuadrático cerca del origen y produce una correlación de corto rango que son las más altas que para cualquier modelo estacionario de segundo grado con el mismo rango práctico. Además, es el más continuo cerca del origen de los considerados aquí. En la parametrización el rango práctico es $\sqrt{3R}$.</span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a>Es importante notar que, si se realiza un análisis basado en semivariogramas y se pretende comparar los parámetros de los semivariogramas obtenidos bajo distintas condiciones, la utilización de modelos teóricos diferentes resulta poco útil. Hay que tener en cuenta que, por ejemplo, los rangos del modelo esférico y el exponencial no son directamente comparables. El modelo esférico es el único que tiene un umbral verdadero, ya que tanto el modelo exponencial como el gaussiano alcanzan el umbral de forma asintótica, o lo que es lo mismo, no lo alcanzan nunca y el modelo lineal no tiene umbral. En consecuencia, los rangos no son directamente equivalentes entre modelos. En este caso, es más conveniente elegir un único modelo para realizar comparaciones de procesos espaciales.</span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a>Los modelos de semivariograma son no lineales a excepción del modelo nugget. Por ello, para la estimación de parámetros estas funciones se usan métodos basados en aproximaciones numéricas. El método de ajuste por mínimos cuadrados ponderados (WLS) es común en la práctica. Para ello, se elige una función y valores iniciales de los parámetros basados en la observación del semivariogramas empírico. El tamaño del conjunto de datos a partir del cual el modelo de semivariograma es ajustado depende del número de *lags* que se elija. Los valores de las clases de *lag* en las cuál el número de pares no es mayor a 30 debieran ser removidos si se ajusta el semivariograma por mínimos cuadrados. Journel y Huijbregts 1978 recomiendan solo usar *lags* menores a la mitad del máximo *lag* en el conjunto de datos. La distribución de los puntos en el espacio determinará para qué *lags* esto es posible.</span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a><span class="fu">## Correlación espacial bivariada</span></span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a><span class="fu">### Coeficiente de correlación</span></span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a>El coeficiente de correlación lineal de Pearson ($r$) es una medida de la magnitud de la correlación lineal entre dos variables. Para calcularlo se supone que se tiene una muestra aleatoria de unidades de análisis donde se han registrado simultáneamente dos variables. El intervalo de confianza para $r$ y el valor $p$ usados para decidir si la correlación poblacional entre ambas variables es cero o distinta de cero, dependen del tamaño de la muestra $n$. El tamaño de la muestra es el número de unidades de análisis independientes.</span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a>Cuando las variables en estudio exhiben autocorrelación espacial, las observaciones de cada una de éstas estarán correlacionadas dentro de un determinado vecindario, es decir, no serán independientes entre sí. Luego, en el caso de datos espaciales, se viola la suposición de observaciones independientes para la prueba de significancia $r$. Una propuesta para contemplar las correlaciones generadas por patrones espaciales es calcular el coeficiente de correlación haciendo un ajuste para determinar el número de observaciones independientes (tamaño de muestra efectivo) para acompañar la inferencia necesaria.</span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a>El coeficiente de correlación modificado <span class="co">[</span><span class="ot">@Clifford_Richardson_Hemon_1989; @Dutilleul_Clifford_Richardson_Hemon_1993</span><span class="co">]</span>, permite evaluar correlación entre dos variables espacializadas en el mismo dominio espacial. La prueba se basa en la modificación de las varianzas y los grados de libertad de la prueba $t$ estándar usada para evaluar significancia del coeficiente de correlación de Pearson y requiere de la estimación del tamaño efectivo de la muestra.</span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a>Considerando $A \subset D$ un grupo de $n$ sitios $A={s_1, s_2,…,s_n}$, se supone que $Z=Z(s_1), Z(s_2),…, Z(s_n)$ y $Y= Y(s_1), Y(s_2),…,Y(s_n)$ con media constante y matriz de varianzas y covarianzas $\Sigma_Z$ y $\Sigma_Y$. Se divide $D$ en los estratos $D_0, D_1, D_2,…$. Entonces $Cov(Z(s_i),Z(s_j))= C_Z(k)$ y $Cov\big(Y(s_i),Y(s_j)\big)= C_Y(k)$, con $s_i, s_j \in D_k$, para $k= 0,1,…$ <span class="co">[</span><span class="ot">@Clifford_Richardson_Hemon_1989</span><span class="co">]</span> sugieren como estimador de $\hat{C}_Y(h)$</span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a>$$ \hat{C}_Y(h) = \frac{\sum_{s_i,s_j \in A_k}{\big( Y(s_i) - \overline{Y} \big) \big( Y(s_j) - \overline{Y} \big)}} {n_k} $$</span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a>donde $n_k$ es la cardinalidad de $D_k$ y y similaridad para $C_Z(k)$. Luego, @Clifford_Richardson_Hemon_1989 sugirió utilizar $n^{-2}\sum_h{n_h\hat{C}_Z(h) \hat{C}_Y(h)}$</span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a>Como un estimador de la varianza condicional de $s_{ZY}=n^{-1} \sum_D{ \big(Z(s)-\overline{Z} \big) \big(Y(s)-\overline{Y} \big) }$. Como resultado se obtiene la prueba $t$ modificada basada en el estadístico $W$</span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a>$$W=n \; s_{ZY} \Big( \sum_h{n_h \hat{C}_Z(h) \hat{C}_Y(h)} \Big)^{-2}$$</span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a>El cual a partir de una serie de aproximaciones a la varianza del coeficiente de correlación de Pearson ($\sigma_r^2$) entre los procesos $Z(s)$ e $Y(s)$ se puede escribir de la siguiente manera $W=(\hat{M}-1)^{1/2}r$, $\hat{M} = 1 + {\hat{\sigma}}_r^{-2}$ y $\hat{\sigma}_r^2 = \frac{\sum_h{n_h \hat{C}_Z(h) \hat{C}_Y(h)}} {n^2 s_Z^2 s_Y^2}$.</span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a>Se define $W$ como una prueba t modificada con $\hat{M}-2$ grados de libertad, donde $\hat{M}$ es el tamaño de muestra efectivo asumiendo bajo hipótesis nula la no correlación entre $Z(s)$ e $Y(s)$. Cuando se presenta una estructura de correlación espacial positiva, generalmente $\hat{M} &lt; n$, si existe estructura de autocorrelación negativa se espera que $\hat{M} &gt; n$.</span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a><span class="fu">### Coeficiente de co-dispersión</span></span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a>Otra forma usada en estadística espacial para explorar patrones de correlaciones o covariaciones entre dos variables espacializadas, es el coeficiente de co-dispersión, que cuantifica la correlación entre dos procesos espaciales para un lag espacial particular sobre un espacio bidimensional. Para dos procesos espaciales intrínsecamente estacionarios ${Z(s):s\in D\subset R^2}$ y ${Y(s):s\in D\subset R^2}$ definidos en una parte de la región $D\subset R^2$, el coeficiente de co-dispersión es definido como:</span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a>$$\rho_{ZY}(h)= \frac{E \Big<span class="co">[</span><span class="ot"> \big(Z(s+h)-Z(s) \big) \big(Y(s+h)-Y(s) \big) \Big</span><span class="co">]</span>}{\sqrt{E \big<span class="co">[</span><span class="ot">Z(s+h)-Z(s) \big</span><span class="co">]</span>^2 E \big<span class="co">[</span><span class="ot">Y(s+h)-Y(s) \big</span><span class="co">]</span>^2}}$$</span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a>La estructura de $\rho_{ZY}$ es computacionalmente similar al coeficiente de correlación de Pearson. Al igual que ese coeficiente, $\rho_{ZY}(h)$, donde los límites superior e inferior definen una asociación espacial negativa o positiva perfecta, respectivamente. Sin embardo, a diferencia del coeficiente de correlación de Pearson, $\rho_{ZY}$ depende del lag $h$, que enfatiza la idea de que la correlación espacial es un valor asociado con una distancia en el plano. El cálculo de la correlación se realiza para diferentes distancias y direcciones en el espacio. Cuando el coeficiente de co-dispersión se calcula para muchas direcciones, es útil mostrar esos valores en un solo gráfico. @Vallejos2015 proponen el mapa de co-dispersión para resumir en un plano los valores de los coeficientes de co-dispersión obtenidos para distintos *lag* espaciales (direcciones y distancias). El gráfico resume la información sobre la correlación entre dos procesos espaciales en forma radial sobre un plano que circunscribe los coeficientes en una semiesfera de radio no mayor al rango del proceso espacial \@ref(fig:figGrafCoDisp). En general las correlaciones espaciales que se observan desde un gráfico de co-dispersión permanecen ocultas en el análisis exploratorio usual y pueden ser distintas a las correlaciones lineales de Pearson no restringidas espacialmente. El gráfico de co-dispersión no debe ser confundido con un mapeo de la co-dispersión de las variables en el espacio de interés. No captura similitudes relacionadas con los patrones o formas que están presentes en los procesos espaciales, sino que captura la dependencia espacial entre los procesos para una distancia h. Los ejes del gráfico de co-dispersión hacen referencia a los *lag* y direcciones y no a las coordenadas de los sitios muestrales originales.</span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a><span class="in">```{r figGrafCoDisp, echo = FALSE, fig.cap= "Gráfico de co-dispersión mostrando la correlación espacial entre dos variables para varios lag espaciales."}</span></span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"figuras/codispersion.jpg"</span>)</span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a><span class="fu">## Interpolación Kriging</span></span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a>La predicción espacial, es decir la predicción de valores de la variable en sitios del campo espacial donde no existen observaciones, usualmente se hace por el método kriging basándose en el semivariograma ajustado. Kriging proporciona el mejor estimador lineal insesgado del valor esperado para el sitio y un error de estimación conocido como varianza kriging. Esta varianza depende del modelo de semivariograma ajustado y de la ubicación en el espacio de los datos observados ya que son los datos observados en distintos sitios los que proveen información para aproximar el valor en el sitio sin dato. Las interpolaciones basadas en semivariograma, se denominan geoestadísticas y tienen ciertas ventajas respecto a interpolaciones determinísticas, como las obtenidas por el método IDW que se basa en las distancias geométricas entre los sitios con datos y el sitio a interpolar. Las observaciones que participan en la predicción se ponderan de forma distinta según la distancia estadística a la que se encuentran.</span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a>Los parámetros del semivariograma son los que gobiernan la asignación de los pesos o ponderaciones de las observaciones vecinas al sitio al cual se le asignará la predicción. El parámetro *nugget* es determinante en la asignación de pesos. si la varianza del error es muy alta, todas las observaciones tenderán a tener el mismo peso en la interpolación. Por el contrario, si la varianza del error es baja, los coeficientes de ponderación serán distintos. Si el rango aumenta, cada punto tendrá mayor peso en la interpolación de otras observaciones. Entre los métodos de interpolación geoestadísticos que utilizan todos los datos simultáneamente se destacan los métodos de kriging ordinario, simple y universal. En el kriging ordinario la media de la variable es estimada localmente. En caso de conocer la media poblacional de la variable, hecho que raramente ocurre, se utiliza el kriging simple. En el kriging universal se estima también la influencia de una tendencia espacial de los datos. La predicción asignada a los puntos incógnita puede realizarse de manera puntual (kriging puntual) o definiendo bloques (kriging en bloques) <span class="co">[</span><span class="ot">@Schabenberger_Gotway_2005; @Webster_Oliver_2007</span><span class="co">]</span>.</span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a><span class="fu">### Kriging ordinario</span></span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a>El kriging ordinario supone que la variación es aleatoria, que existe dependencia espacial y que el proceso espacial subyacente es intrínsecamente estacionario con media constante y varianza que depende solo de la separación en distancia entre los sitios y no de su posición. La predicción kriging resulta de una combinación lineal de los datos observados. Supongamos que los valores de $Z$, han sido muestreados en los puntos $s_1{,s}_2,\ldots,s_n$, para generar N datos $z(s_i),\ i=1,\ 2,\ldots, N$. Para el caso del kriging ordinario puntual se predice $Z$ en cualquier nuevo punto $s_0$ mediante:</span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a>$$\hat{Z}(s_0)=\sum_{i=1}^{N}{w_iz(s_i)}$$</span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a>donde $w$ son los pesos asignados a cada observación. Para asegurar que la estimación del valor esperado para el sitio sea insesgada y de mínima varianza, los pesos son dado de manera que:</span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a>$$\sum_{i = 1}^{N}{w_i=1}$$</span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a>$$E\big<span class="co">[</span><span class="ot">\hat{Z}(s_0)-z(s_0)\big</span><span class="co">]</span>=0$$</span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a>Var\big<span class="co">[</span><span class="ot">\hat{Z}(s_0) \big</span><span class="co">]</span> &amp; = E\big<span class="co">[</span><span class="ot">\hat{Z}(s_0) - z(s_0)^2 \big</span><span class="co">]</span> <span class="sc">\\</span>&amp;= 2\sum_{i=1}^{N}{w_i\gamma(s_i-s_0)-\sum_{i=1}^{N}\sum_{j=1}^{N}{w_iw_j\gamma(s_i-s_j)}}</span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a>donde la cantidad $\gamma(s_i - s_0)$ es la semivarianza de $Z$ entre el punto de muestreo $i$ y el punto objetivo $x_0$ y $\gamma(s_i - s_j)$ es la semivariancia entre los puntos de muestreo $i$ y $j$. Las semivarianzas se derivan del modelo teórico de semivariograma, debido a que no hay existen valores de semivarianzas entre los sitios con datos y los sitios objetivos donde no existen valores observados. Si un sitio objetivo también es un punto de muestreo, el kriging puntual devuelve el valor observado en ese sitio y la varianza de estimación es cero. El kriging puntual es un interpolador exacto en este sentido. El siguiente paso en kriging es encontrar los pesos que minimizan la varianza de la predicción sujeto a la restricción de que la suman de los pesos se igual a 1.</span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a>$$\sum_{i=1}^{N}w_i\gamma(s_i-s_0)+\psi(s_0)=\gamma(s_j-s_0) \forall j$$</span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a>La cantidad $\psi (s_0)$ es el multiplicador de Lagrange introducido para lograr la minimización. La solución de las ecuaciones de kriging proporciona los pesos para las ponderaciones y la varianza de predicción se obtiene de la siguiente forma:</span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a>$$\sigma^2(s_0)=\sum_{i=1}^{N}{w_i\gamma(}s_i-s_0)+\ \psi(s_0)$$</span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a><span class="fu">### Kriging en bloques</span></span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a>El kriging en bloques consiste en estimar directamente el valor promedio de la variable sobre un soporte mayor que el soporte de los datos (bloque). Intuitivamente, la idea es calcular mediante kriging puntual los valores en todos los puntos de una superficie o bloque y usar la media de las predicciones como estimador del valor esperado para el sitio. La estimación para cualquier bloque sigue siendo un promedio ponderado de los datos, $z\ (s_1),\ z\ (s_2),\ ...,\ z\ (s_N)$:</span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a>$$\hat{Z}(B)=\sum_{i=1}^{N}{w_iz(s_i)}$$</span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a>Los factores de ponderación se obtienen nuevamente para minimizar la varianza del error y para obtener un estimador insesgado de la media. La grilla de predicción sobre la que se construye el mapa de variabilidad espacial presenta una dimensión menor que la de los bloques, asegurándose la obtención de un mapa más suavizado respecto al obtenido con kriging puntual. El kriging en bloques ha mostrado ser efectivo a la hora de reducir errores que pueden trasladarse en los mapas como consecuencia de inexactitudes de datos puntuales.</span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a><span class="fu">### Kriging local</span></span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a>Hemos dicho que los pesos de las observaciones en la predicción geoestadística son funciones de las semivarianzas entre las observaciones en sitios en el vecindario, $\gamma(s_i-s_j)$, y entre cada punto de muestreo y el punto a predecir, $\gamma(s_i-s_0)$. En general solo los puntos cercanos al punto a predecir tienen un peso significativo. Cuando la relación nugget:sill es pequeña el interpolador kriging es visto como un predictor local, donde para la predicción de $Z(s_0)$ participarán sólo datos de puntos dentro de la proximidad de $s_0$ (*kriging neighborhood* o kriging local). El kriging local esencialmente asigna pesos $w(s_0)=0$ para todos los puntos $s_i$ fuera de la zona en la que se quiere predecir. Por otra parte, esto permite que podemos aceptar el supuesto de estacionariedad local (o cuasi estacionariedad), es decir se puede restringir el supuesto de estacionariedad de la media a los vecindarios del kriging. Lo que sucede en distancias mayores a las del vecindario del sitio no será de importancia para la predicción en el sitio. La predicción y varianza kriging dependen principalmente de la parte del semivariograma cercana al origen, por ello es de importancia modelar bien el semivariograma en estos lugares, *i.e.* dar más peso a las semivarianzas experimentales cercanas al origen. No hay reglas para definir el vecindario para implementar el kriging local, aunque cuando el nugget es relativamente bajo se pude definir un radio de vecindad cercano al rango o rango práctico del modelo de semivariograma ajustado. Cuando el efecto nugget es importante el radio de vecindad debería ser mayor al rango ya que es probable que puntos más distantes tengan aún peso significativo. Otra alternativa para definir el vecindario se basa en términos de un número mínimo y máximo de datos cercanos al punto a predecir. Algunos autores recomiendan utilizar un mínimo de 7 vecinos y un máximo de 20.</span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a><span class="fu">### Kriging universal</span></span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a>La suposición de estacionariedad intrínseca no se cumple cuando existen tendencias geográficas pronunciada de naturaleza sistemática y no aleatoria. La tendencia puede ser regional, es decir, una variación sistemática en toda la región de interés o local de un punto a otro dentro de la región estudiada. La existencia de tendencias puede ser explorada graficando los datos de la variable analizada en función a la variable que se supone genera la tendencia espacial. La tendencia también se manifiesta en los semivariogramas experimentales con un incremento de la semivarianza con la distancia que no tiene límites.  Si hay tendencia, entonces $\mu$ ya no es constante, sino que depende de s. Además, el semivariograma experimental de los datos ya no estima el semivariograma de los errores aleatorios, $\varepsilon(s)$. Se necesita estimar el semivariograma de $\varepsilon(s) = Z (s) - \mu(s)$. Cuando este variograma es el input del kriging, el proceso de interpolación se conoce como "kriging universal" y la predicción se obtiene como:</span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a>$$\hat{Z}(s_0)=\sum_{i=1}^{N}{w_i \; f_kz(s_i)}$$</span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a>donde $f_k$ es función de las coordenadas espaciales.</span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a><span class="fu">### Validación cruzada</span></span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a>La predicción implica asignar nuevos valores de las variables respuesta a contextos o escenarios que no corresponden al conjunto de escenarios medidos, es decir no se trata de aquellos sitios que utilizaron para realizar la predicción espacial. Entre las alternativas para estimar la exactitud de la predicción existen las técnicas de validación cruzada o técnicas de partición del conjunto de datos en datos de calibración y datos de validación <span class="co">[</span><span class="ot">@Efron_Hastie_2016</span><span class="co">]</span>. Es necesario identificar un grupo de observaciones sobre las que se ajustará el modelo o el método que permite predecir, usualmente llamado datos de calibración, y otro grupo que se usará para validar, llamado datos de validación. El modelo (semivariograma teórico) se ajusta sobre el conjunto de datos de entrenamiento y posteriormente se usa para la predicción de interés, con observaciones del subconjunto de validación. Seguidamente, los valores observados del conjunto de validación se comparar con los valores predichos por el modelo. Usualmente el proceso se repite cruzando el rol de los subconjuntos de datos, es decir el que era de validación pasa a ser de calibración y viceversa.</span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a>Sin embargo, otras estrategias pueden ser usadas para la selección de los datos de entrenamiento y validación. Una es particionar en forma aleatoria los datos en ambos conjuntos. Otro tipo de validación cruzada es dejando uno fuera (*Leave-One-Out*) donde se utiliza una sola observación para conformar el subconjunto de validación y se deja al resto como subconjunto de entrenamiento. El modelo se ajusta utilizando las $n – 1$ observaciones de entrenamiento y se obtiene una predicción para la observación excluida. Este proceso se repite $n$ veces. Otro tipo de validación cruzada es $k-fold$, donde las observaciones se dividen aleatoriamente en $k$ grupos de aproximadamente igual tamaño. Uno de los $k$ grupos se emplea como subconjunto de validación, mientras que el resto de los grupos se emplean para entrenar el modelo. El proceso de validación cruzada es repetido durante k iteraciones, con cada uno de los subconjuntos de datos de prueba. Un valor común de $k$ que puede dar buenos resultados en cuanto al equilibrio sesgo-varianza para estimar el error de predicción es $k=10$. Si el modelo tuvo un buen desempeño, los residuos de la validación cruzada serán pequeños, su media será cercana a cero y no presentarán estructura.</span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a>En la evaluación de modelos geoestadísticos, los valores predichos de kriging $\hat{Z}(s_i)$ se comparan con los observados $z(s_i)$, y se calcula una medida resumen que caracteriza el resultado de la comparación. Algunas de estas medidas resumen son:</span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a>Error medio</span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a>$$ME=\frac{1}{N}\sum_{i=1}^{N}\big<span class="sc">\{</span>z(s_i)-\hat{Z}(s_i)\big<span class="sc">\}</span>$$</span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a>donde $N$ es el número de observaciones, $z(s_i)$ es el valor verdadero en $s_i$ y $\hat{Z}(s_i)$ es el valor predicho en ese punto.</span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a>Error cuadrático medio (Mean Square Error, MSE):</span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a>$$MSE=\frac{1}{N}\sum_{i=1}^{N}{\big<span class="sc">\{</span>z(s_i)-\hat{Z}(s_i)\big<span class="sc">\}</span>^2}$$</span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a>Raíz del error cuadrático medio:</span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a>$$RMSE=\frac{1}{N}\sqrt{\sum_{i=1}^{N}\big<span class="sc">\{</span>z(s_i)-\hat{Z}(s_i)\big<span class="sc">\}</span>^2}$$</span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a>Media del cociente del error cuadrático (Mean Squared Deviation Ratio, MSDR):</span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a>$$MSDR=\frac{1}{N} \sum_{i=1}^{N}\frac{ \big<span class="sc">\{</span> z(s_i) - \hat{Z}(s_i) \big<span class="sc">\}</span>^2} {\hat{\sigma}^2(s_i)}$$</span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a>donde $\hat{\sigma}^2(s_i)$ es la varianza de la predicción kriging en el punto $s_i$.</span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a>Para el caso de datos espaciales, no solo es necesario disponer de una medida de error de predicción global, sino que también hay que evaluar del error de la predicción en cada sitio específico, *i.e.* dimensionar el error puntual de la predicción espacial.</span>
</code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">Guía para el análisis de datos espaciales. Aplicaciones en agricultura</div>   
    <div class="nav-footer-right">Este libro se construyo con <a href="https://quarto.org/">Quarto</a>.</div>
  </div>
</footer>


<script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>